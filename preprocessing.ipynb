{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "\n",
    "from recording import Recording\n",
    "import utils as utl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# global settings\n",
    "params = {\n",
    "    'bin_size'      : 0.1,   # bin size in s\n",
    "    'thresh_rate'   : 1,     # min firing rate in Hz\n",
    "    'thresh_sw'     : 0.5,   # min spike width in ms\n",
    "    'thresh_trials' : 0.9,   # number of trials to keep in %\n",
    "    'scoring'       : 'r2',  # see https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    'signal'        : 'fr',\n",
    "}\n",
    "\n",
    "# define trial epochs \n",
    "# epoch_name : (start, end, alignment)\n",
    "#              note that this defines the half-open interval [start, end)\n",
    "#              note that lick times may fall between bins, because bins are aligned to cue\n",
    "epochs = {\n",
    "    'all'       : (None, None, 'cue'), # None only works with 'cue' alignment\n",
    "    'pre_cue'   : (-.6,  .0,   'cue'),\n",
    "    'post_cue1' : ( .0,  .6,   'cue'),\n",
    "    'post_cue2' : ( .6, 1.2,   'cue'),\n",
    "    'pre_lick'  : (-.6,  .0,  'lick'),\n",
    "    'post_lick' : ( .0,  .6,  'lick'),\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select units: single region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # single ALM probe\n",
    "# rec1 = Recording('./data/zidan/ALM_ALM/MK22_20230301/MK22_20230301_2H2_g0_JRC_units_probe1.mat')\n",
    "# rec2 = None\n",
    "\n",
    "# # ALM-ALM\n",
    "# rec1 = Recording('./data/zidan/ALM_ALM/MK22_20230301/MK22_20230301_2H2_g0_JRC_units_probe2.mat')\n",
    "# rec2 = Recording('./data/zidan/ALM_ALM/MK22_20230301/MK22_20230301_2H2_g0_JRC_units_probe1.mat')\n",
    "\n",
    "# ALM-Str (imec0: STR)\n",
    "rec2 = Recording('./data/zidan/ALM_STR/ZY78_20211015/ZY78_20211015NP_g0_JRC_units.mat')\n",
    "rec1 = Recording('./data/zidan/ALM_STR/ZY78_20211015/ZY78_20211015NP_g0_imec0_JRC_units.mat')\n",
    "\n",
    "# # ALM-Thal (imec0: Thal)\n",
    "# rec2 = Recording('./data/zidan/ALM_Thal/ZY113_20220617/ZY113_20220617_NPH2_g0_JRC_units.mat')\n",
    "# rec1 = Recording('./data/zidan/ALM_Thal/ZY113_20220617/ZY113_20220617_NPH2_g0_imec0_JRC_units.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select units and trials, and bin data\n",
    "dfx_bin, dfy_bin = utl.select_data(rec1, rec2=rec2, params=params)\n",
    "\n",
    "# subtract baseline\n",
    "dfx_bin0 = utl.subtract_baseline(dfx_bin, rec1.df_spk)\n",
    "dfy_bin0 = utl.subtract_baseline(dfy_bin, rec2.df_spk)\n",
    "\n",
    "# # optional: filter some epoch\n",
    "# dfx_bin0 = utl.select_epoch(dfx_bin0, epochs['all'], rec1.df_trl)\n",
    "# dfy_bin0 = utl.select_epoch(dfy_bin0, epochs['all'], rec2.df_trl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression (= ridge with alpha=0)\n",
    "lin_mods = utl.ridge_regression(dfx_bin0, dfy_bin0, scoring=params['scoring'], alphas=[0])\n",
    "lin_mod = lin_mods.best_estimator_\n",
    "\n",
    "# ridge\n",
    "ridge_mods = utl.ridge_regression(dfx_bin0, dfy_bin0, scoring=params['scoring'], alphas=np.logspace(-13, 13, 27))\n",
    "ridge_mod = ridge_mods.best_estimator_\n",
    "utl.plot_gridsearch(ridge_mods, 'ridge', other_mods={'linear': lin_mods}, logscale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RRR\n",
    "rr_mods = utl.reduced_rank_regression(dfx_bin0, dfy_bin0, scoring=params['scoring'])\n",
    "rr_mod = rr_mods.best_estimator_\n",
    "utl.plot_gridsearch(rr_mods, 'reduced rank', other_mods={'linear': lin_mods, 'ridge': ridge_mods}, logscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "Y_pred, scores = utl.get_ypred(dfx_bin0, dfy_bin0, ridge_mod, scoring=params['scoring'])\n",
    "utl.plot_mean_response(dfy_bin0, Y_pred, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remote batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch process all recordings\n",
    "p_root = Path(r'X:\\Users\\Zidan\\DataForNico')\n",
    "\n",
    "if not p_root.is_dir():\n",
    "    print('Invalid rood dir. No access to network drive?')\n",
    "\n",
    "else: \n",
    "    p_dirs = [ p for p in p_root.glob('*/*/') if p.is_dir() ]\n",
    "\n",
    "name2region = {\n",
    "    'MK22_20230301_2H2_g0_JRC_units_probe1.mat' : 'ALM1',\n",
    "    'MK22_20230301_2H2_g0_JRC_units_probe2.mat' : 'ALM2',\n",
    "    'MK22_20230303_2H2_g0_JRC_units_probe1.mat' : 'ALM1',\n",
    "    'MK22_20230303_2H2_g0_JRC_units_probe2.mat' : 'ALM2',\n",
    "    'MK25_20230314_2H2_g0_JRC_units_probe1.mat' : 'ALM1',\n",
    "    'MK25_20230314_2H2_g0_JRC_units_probe2.mat' : 'ALM2',\n",
    "    'ZY78_20211015NP_g0_imec0_JRC_units.mat'    : 'STR',\n",
    "    'ZY78_20211015NP_g0_JRC_units.mat'          : 'ALM',\n",
    "    'ZY82_20211028NP_g0_imec0_JRC_units.mat'    : 'STR',\n",
    "    'ZY82_20211028NP_g0_JRC_units.mat'          : 'ALM',\n",
    "    'ZY83_20211108NP_g0_imec0_JRC_units.mat'    : 'STR',\n",
    "    'ZY83_20211108NP_g0_JRC_units.mat'          : 'ALM',\n",
    "    'ZY113_20220617_NPH2_g0_imec0_JRC_units.mat': 'THA',\n",
    "    'ZY113_20220617_NPH2_g0_JRC_units.mat'      : 'ALM',\n",
    "    'ZY113_20220618_NPH2_g0_imec0_JRC_units.mat': 'THA',\n",
    "    'ZY113_20220618_NPH2_g0_JRC_units.mat'      : 'ALM',\n",
    "    'ZY113_20220620_NPH2_g0_imec0_JRC_units.mat': 'THA',\n",
    "    'ZY113_20220620_NPH2_g0_JRC_units.mat'      : 'ALM',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot response, binned at 1 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p_mat in p_root.glob('**/*mat'):\n",
    "    \n",
    "    # load recording and create missing dataframes\n",
    "    print(p_mat)\n",
    "\n",
    "    rec = Recording(p_mat, calc_psth=True)\n",
    "    rec.plot_psth(path=rec.path_psth.with_suffix('.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_wrapper(p_out, params, recA, recB):\n",
    "\n",
    "    # create folder\n",
    "    p_out.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    # path for params.json\n",
    "    p_json = p_out / 'params.json'\n",
    "    if p_json.exists():\n",
    "        print(f'params.json found. Skipping {p_out}')\n",
    "        return \n",
    "    \n",
    "    # load data\n",
    "    dfx_bin, dfy_bin = utl.select_data(recA, rec2=recB, params=params)\n",
    "\n",
    "    if params['subtract_baseline']:\n",
    "        dfx_bin = utl.subtract_baseline(dfx_bin)\n",
    "        dfy_bin = utl.subtract_baseline(dfy_bin)\n",
    "\n",
    "    # linear regression (= ridge with alpha=0)\n",
    "    lin_mods = utl.ridge_regression(dfx_bin, dfy_bin, scoring=params['scoring'], alphas=[0])\n",
    "    lin_mod = lin_mods.best_estimator_\n",
    "    utl.save_cv_results(lin_mods, path=p_out / 'reg_linear.parquet')\n",
    "\n",
    "    # ridge regression\n",
    "    ridge_mods = utl.ridge_regression(dfx_bin, dfy_bin, scoring=params['scoring'], alphas=np.logspace(-13, 13, 27))\n",
    "    ridge_mod = ridge_mods.best_estimator_\n",
    "    utl.save_cv_results(ridge_mods, path=p_out / 'reg_ridge.parquet')\n",
    "\n",
    "    # RRR\n",
    "    rr_mods = utl.reduced_rank_regression(dfx_bin, dfy_bin, scoring=params['scoring'])\n",
    "    rr_mod = rr_mods.best_estimator_\n",
    "    utl.save_cv_results(rr_mods, path=p_out / 'reg_rrr.parquet')\n",
    "\n",
    "    # plot regressions\n",
    "    utl.plot_gridsearch(ridge_mods, 'ridge', other_mods={'linear': lin_mods}, logscale=True, path=p_out / 'reg_ridge.png')\n",
    "    utl.plot_gridsearch(rr_mods, 'reduced rank', other_mods={'linear': lin_mods, 'ridge': ridge_mods}, logscale=False, path=p_out / 'reg_rrr.png')\n",
    "\n",
    "    # prediction\n",
    "    Y_pred, scores = utl.get_ypred(dfx_bin, dfy_bin, ridge_mod, scoring=params['scoring'])\n",
    "    utl.plot_mean_response(dfy_bin, Y_pred, scores, path=p_out / 'pred_ridge.png')\n",
    "    pd.Series(scores, name=params['scoring']).to_csv(p_out / 'pred_ridge_scores.csv', index=False)\n",
    "\n",
    "    # save params\n",
    "    pd.Series(params).to_json(p_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_params = {\n",
    "    # bin 0.05\n",
    "    'all_depth_0.05': {\n",
    "        'bin_size'          : 0.05, \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  True\n",
    "        },\n",
    "    'all_depth_raw_0.05': {\n",
    "        'bin_size'          : 0.05,  \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  False\n",
    "        },\n",
    "\n",
    "    # bin 0.1\n",
    "    'all_depth_0.1': {\n",
    "        'bin_size'          : 0.1, \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  True\n",
    "        },\n",
    "    'all_depth_raw_0.1': {\n",
    "        'bin_size'          : 0.1,  \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  False\n",
    "        },\n",
    "\n",
    "        ## all spike width\n",
    "        'all_depth_allSW_0.1': {\n",
    "            'bin_size'          : 0.1, \n",
    "            'thresh_sw'         : 0.0,  \n",
    "            'thresh_rate'       : 1,    \n",
    "            'thresh_trials'     : 0.9,  \n",
    "            'scoring'           : 'r2', \n",
    "            'subtract_baseline' :  True\n",
    "            },\n",
    "        'all_depth_raw_allSW_0.1': {\n",
    "            'bin_size'          : 0.1,  \n",
    "            'thresh_sw'         : 0.0,  \n",
    "            'thresh_rate'       : 1,    \n",
    "            'thresh_trials'     : 0.9,  \n",
    "            'scoring'           : 'r2', \n",
    "            'subtract_baseline' :  False\n",
    "            },\n",
    "\n",
    "    # bin 0.2\n",
    "    'all_depth_0.2': {\n",
    "        'bin_size'          : 0.2, \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  True\n",
    "        },\n",
    "    'all_depth_raw_0.2': {\n",
    "        'bin_size'          : 0.2,  \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  False\n",
    "        },\n",
    "\n",
    "    # bin 0.5\n",
    "    'all_depth_0.5': {\n",
    "        'bin_size'          : 0.5, \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  True\n",
    "        },\n",
    "    'all_depth_raw_0.5': {\n",
    "        'bin_size'          : 0.5,  \n",
    "        'thresh_sw'         : 0.5,  \n",
    "        'thresh_rate'       : 1,    \n",
    "        'thresh_trials'     : 0.9,  \n",
    "        'scoring'           : 'r2', \n",
    "        'subtract_baseline' :  False\n",
    "        },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, params in d_params.items():\n",
    "    print(f'>>>> starting parameter set {name}....')\n",
    "\n",
    "    for p_dir in p_dirs:\n",
    "\n",
    "        print(p_dir)\n",
    "\n",
    "        # load recordings\n",
    "        p_matA, p_matB = [ *p_dir.glob('*.mat')]\n",
    "        recA, recB = Recording(p_matA), Recording(p_matB)\n",
    "        regA, regB = name2region[p_matA.name], name2region[p_matB.name]\n",
    "\n",
    "        # regA -> regB\n",
    "        p_out = p_dir / f'{name}/{regA}_{regB}'\n",
    "        proc_wrapper(p_out, params, recA, recB)\n",
    "\n",
    "        # regB -> regA\n",
    "        p_out = p_dir / f'{name}/{regB}_{regA}'\n",
    "        proc_wrapper(p_out, params, recB, recA)\n",
    "\n",
    "        # regA\n",
    "        p_out = p_dir / f'{name}/{regA}'\n",
    "        proc_wrapper(p_out, params, recA, None)\n",
    "\n",
    "        # regB\n",
    "        p_out = p_dir / f'{name}/{regB}'\n",
    "        proc_wrapper(p_out, params, recB, None)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(ps_csv):\n",
    "\n",
    "    dfs = []\n",
    "    for p_csv in ps_csv:\n",
    "\n",
    "        folder = p_csv.parent.name\n",
    "        rec = p_csv.parent.parent.parent.name\n",
    "        pro = p_csv.parent.parent.parent.parent.name\n",
    "        ani = rec.split('_')[0]\n",
    "        df = pd.read_csv(p_csv)\n",
    "\n",
    "\n",
    "        dfs.append(pd.DataFrame(data={\n",
    "            'unit': df.index,\n",
    "            'score': df.iloc[:, 0],\n",
    "            'region': folder.replace(folder.split('_')[0] + '_', ''),\n",
    "            'interaction': folder,\n",
    "            'recording': rec,\n",
    "            'animal': ani,\n",
    "            'probes': pro,\n",
    "        })\n",
    "        )\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df.loc[:, 'interaction_'] = df.loc[:, 'interaction'].map(lambda x: x.replace('ALM1', 'ALM').replace('ALM2', 'ALM'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in d_params.keys():\n",
    "    print(name)\n",
    "    \n",
    "    p_plot = p_root / 'plots/'\n",
    "    p_plot.mkdir(exist_ok=True)\n",
    "\n",
    "    p_csvs = [ *p_root.glob(f'**/{name}/**/pred_ridge_scores.csv') ]\n",
    "    if not p_csvs:\n",
    "        print(f'No CSV files found: skipping {name}')\n",
    "        continue\n",
    "    \n",
    "    df = load_scores(p_csvs)\n",
    "\n",
    "    g = sns.catplot(df, x='interaction', y='score', col='probes', hue='recording', sharex=False, facet_kws={'ylim': (-1, 1)}, dodge=True)\n",
    "    g.fig.savefig(p_plot / f'scores_{name}.png')\n",
    "    plt.close(g.fig)\n",
    "\n",
    "    df.loc[:, '_sort'] = df.loc[:, 'interaction_'].str.len()\n",
    "    d = df.sort_values(by=['_sort', 'interaction_'])\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    sns.stripplot(data=d, ax=ax, x='interaction_', y='score', hue='recording', dodge=True)\n",
    "    ax.set_ylim((-1, 1))\n",
    "    fig.savefig(p_plot / f'scores_pooled_{name}.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selective comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline subtraction\n",
    "\n",
    "name = 'all_depth_0.1_baseline_subtraction'\n",
    "p_plot = p_root / 'plots/compare_settings'\n",
    "p_plot.mkdir(exist_ok=True)\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.1/**/pred_ridge_scores.csv')  ]\n",
    "df1 = load_scores(p_csvs)\n",
    "df1.loc[:, 'sub_baseline'] = True\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_raw_0.1/**/pred_ridge_scores.csv')  ]\n",
    "df2 = load_scores(p_csvs)\n",
    "df2.loc[:, 'sub_baseline'] = False\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "g = sns.catplot(data=df, \n",
    "                x='interaction', y='score', col='recording', col_wrap=3, hue='sub_baseline',\n",
    "                sharex=False, facet_kws={'ylim': (-1, 1)},\n",
    "                kind='box', whis=0, fliersize=0, palette='pastel',\n",
    "                dodge=True, height=4, aspect=.8)\n",
    "g.map(sns.stripplot, 'interaction', 'score', 'sub_baseline', dodge=True, palette='deep', edgecolor='auto', linewidth=.5)\n",
    "g.fig.savefig(p_plot / f'scores_{name}.png')\n",
    "plt.close(g.fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin size\n",
    "name = 'all_depth_bin_size'\n",
    "p_plot = p_root / 'plots/compare_settings'\n",
    "p_plot.mkdir(exist_ok=True)\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.05/**/pred_ridge_scores.csv')  ]\n",
    "df1 = load_scores(p_csvs)\n",
    "df1.loc[:, 'bin_size'] = 0.05\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.1/**/pred_ridge_scores.csv')  ]\n",
    "df2 = load_scores(p_csvs)\n",
    "df2.loc[:, 'bin_size'] = 0.1\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.2/**/pred_ridge_scores.csv')  ]\n",
    "df3 = load_scores(p_csvs)\n",
    "df3.loc[:, 'bin_size'] = 0.2\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.5/**/pred_ridge_scores.csv')  ]\n",
    "df4 = load_scores(p_csvs)\n",
    "df4.loc[:, 'bin_size'] = 0.5\n",
    "\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "g = sns.catplot(data=df, \n",
    "                x='interaction', y='score', col='recording', col_wrap=3, hue='bin_size',\n",
    "                sharex=False, facet_kws={'ylim': (-1, 1)},\n",
    "                kind='box', whis=0, fliersize=0, palette='pastel',\n",
    "                dodge=True, height=4, aspect=1.2)\n",
    "g.map(sns.stripplot, 'interaction', 'score', 'bin_size', dodge=True, palette='deep', edgecolor='auto', linewidth=.5)\n",
    "g.fig.savefig(p_plot / f'scores_{name}.png')\n",
    "plt.close(g.fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike width\n",
    "\n",
    "name = 'all_depth_0.1_spike_width'\n",
    "p_plot = p_root / 'plots/compare_settings'\n",
    "p_plot.mkdir(exist_ok=True)\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_0.1/**/pred_ridge_scores.csv')  ]\n",
    "df1 = load_scores(p_csvs)\n",
    "df1.loc[:, 'min_spike_width'] = 0.5\n",
    "\n",
    "p_csvs = [ *p_root.glob('**/all_depth_allSW_0.1/**/pred_ridge_scores.csv')  ]\n",
    "df2 = load_scores(p_csvs)\n",
    "df2.loc[:, 'min_spike_width'] = 0.0\n",
    "\n",
    "df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "g = sns.catplot(data=df, \n",
    "                x='interaction', y='score', col='recording', col_wrap=3, hue='min_spike_width',\n",
    "                sharex=False, facet_kws={'ylim': (-1, 1)},\n",
    "                kind='box', whis=0, fliersize=0, palette='pastel',\n",
    "                dodge=True, height=4, aspect=1.2)\n",
    "g.map(sns.stripplot, 'interaction', 'score', 'min_spike_width', dodge=True, palette='deep', edgecolor='auto', linewidth=.5)\n",
    "g.fig.savefig(p_plot / f'scores_{name}.png')\n",
    "plt.close(g.fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## all vs one\n",
    "# get scores for best alpha\n",
    "ridge_scores = {}\n",
    "alpha = ridge_mod.get_params()['mod__alpha']\n",
    "\n",
    "for y, u in zip(Y.T, dfy_mat.columns):\n",
    "    mods = utl.ridge_regression(X, y, alphas=[alpha])\n",
    "    mod = mods.best_estimator_\n",
    "    ridge_scores[u] = mod.score(X, y)\n",
    "\n",
    "# prediction\n",
    "Y_pred = ridge_mod.predict(X)\n",
    "dfy_pred = utl.matrix2df(Y_pred, dfy)\n",
    "\n",
    "# plot true and predicted with score\n",
    "utl.plot_psth(dfy, bin_size, df2=dfy_pred, scores=ridge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def matrix2df(X, dfx):\n",
    "\n",
    "    t = dfx.loc[:, 'T'].values\n",
    "    bins = dfx.loc[:, 'bins'].values\n",
    "    trl = dfx.loc[:, 'trial'].values\n",
    "    t2bins = pd.Series(index=t, data=bins).to_dict()   \n",
    "    t2trl = pd.Series(index=t, data=trl).to_dict()   \n",
    "    \n",
    "    df_piv = pd.pivot_table(dfx, values='dfr', index='T', columns='unit').fillna(0)\n",
    "    df_piv.loc[:, :] = X\n",
    "    df_stack = df_piv.stack()\n",
    "    dfr = df_stack.values\n",
    "    t, unt  = [ *df_stack.index.to_frame().values.T ]\n",
    "    df = pd.DataFrame(data={\n",
    "        'unit': unt.astype(int),\n",
    "        'trial': [ t2trl[i] for i in t ],\n",
    "        'dfr': dfr,\n",
    "        'bins': [ t2bins[i] for i in t ],\n",
    "        'T': t,\n",
    "    })\n",
    "\n",
    "    return df\n",
    "    \n",
    "# all vs one for best ridge model\n",
    "def all_vs_one(dfx, dfy, ridge_mod):\n",
    "\n",
    "    alpha = ridge_mod.get_params()['mod__alpha']\n",
    "\n",
    "    X, Y = utl.get_matrix(dfx), utl.get_matrix(dfy)\n",
    "    units = dfy.loc[:, 'unit'].unique()\n",
    "\n",
    "    ridge_scores = {}\n",
    "\n",
    "    for y, u in zip(Y.T, units):\n",
    "        mods = utl.ridge_regression(X, y, alphas=[alpha])\n",
    "        mod = mods.best_estimator_\n",
    "        ridge_scores[u] = mod.score(X, y)\n",
    "\n",
    "    # prediction\n",
    "    Y_pred = ridge_mod.predict(X)\n",
    "    dfy_pred = utl.matrix2df(Y_pred, dfy)\n",
    "\n",
    "    return dfy_pred, ridge_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw vs trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './data/zidan/ALM_ALM/MK22_20230301/MK22_20230301_2H2_g0_JRC_units_probe2.mat'\n",
    "rec = Recording(p, force_overwrite=True)\n",
    "\n",
    "from scipy.io import loadmat\n",
    "m = loadmat(p, squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i, u in enumerate(m['unit']):\n",
    "    t = vars(u)['RawSpikeTimes']\n",
    "\n",
    "    d = pd.DataFrame(data={\n",
    "        'T': t,\n",
    "        'unit': i + 1,\n",
    "    })\n",
    "\n",
    "\n",
    "    df = pd.concat([df, d], ignore_index=True)\n",
    "\n",
    "raw = df.loc[ df.loc[:, 'unit'] == 1 ].loc[:, 'T'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk = vars(m['unit'][0])['SpikeTimes']\n",
    "idx = vars(m['unit'][0])['Trial_idx_of_spike']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0s = np.array([vars(i)['onset'] for i in m['trial_info']]) / 2.5e4\n",
    "behavior = vars(vars(m['unit'][0])['Behavior'])\n",
    "t_lck = behavior['First_lick']\n",
    "t_cue = behavior['Sample_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(t_cue - t_lck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "for i in range(2, 30):\n",
    "    mask = idx == i\n",
    "    s = spk[mask]\n",
    "\n",
    "\n",
    "    # t0 = df_trl.loc[ df_trl.loc[:, 'trial'] == i ].loc[:, 'T_0'].item()\n",
    "    l = t_lck[i + 1]\n",
    "    c = t_cue[i + 1]\n",
    "    t0 = t0s[i-1]\n",
    "    mask = (s > (c-2)) & (s < ( l + 2) )\n",
    "    s = s[mask]\n",
    "\n",
    "    ax.axvline(t0, c='C0', ls=':', lw=1)\n",
    "    ax.axvline(t0 + c, c='C1', ls=':', lw=1)\n",
    "    ax.axvline(l + t0, c='C2', ls=':', lw=1)\n",
    "\n",
    "    ax.eventplot(s + t0, lineoffsets=i, color=f'C{i}')\n",
    "\n",
    "mask = raw < 300\n",
    "ax.eventplot(raw[mask], lineoffsets=i + 1, ls='-')\n",
    "\n",
    "ax.set_xlabel('times [s]')\n",
    "ax.set_ylabel('trial index')\n",
    "ax.set_xlim((0, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new spike processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = './data/zidan/ALM_ALM/MK22_20230301/MK22_20230301_2H2_g0_JRC_units_probe2.mat'\n",
    "rec = Recording(p, force_overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df = rec.df_spk.groupby('unit').get_group(14)\n",
    "for trl, d in df.groupby('trial'):\n",
    "    x = d.loc[:, 't'].values\n",
    "    ax.eventplot(x, lineoffsets=trl)\n",
    "ax.set_xlim((-1, 4))\n",
    "ax.set_ylim((0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "df = rec.df_spk.groupby('unit').get_group(14)\n",
    "for trl, d in df.groupby('trial'):\n",
    "    x = d.loc[:, 't'].values\n",
    "    ax.eventplot(x, lineoffsets=trl)\n",
    "ax.set_xlim((-1, 4))\n",
    "# ax.set_ylim((0, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rec.df_spk = rec._load_spike_times()\n",
    "# rec.df_psth = rec._calculate_psth()\n",
    "rec.plot_psth(unts=[14], xlims=(-1, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec.df_spk = rec._load_spike_times()\n",
    "print('loaded')\n",
    "rec.df_psth = rec._calculate_psth()\n",
    "print('loaded')\n",
    "rec.plot_psth(unts=[14], xlims=(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## only rewarded trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = rec1.df_trl.loc[ rec1.df_trl.loc[:,'response'] == 'Reward', 'trial' ]\n",
    "m = rec1.df_prec.loc[:, 'trial'].isin(t)\n",
    "rec1.df_prec = rec1.df_prec.loc[ m ]\n",
    "\n",
    "t = rec2.df_trl.loc[ rec2.df_trl.loc[:,'response'] == 'Reward', 'trial' ]\n",
    "m = rec2.df_prec.loc[:, 'trial'].isin(t)\n",
    "rec2.df_prec = rec2.df_prec.loc[ m ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
