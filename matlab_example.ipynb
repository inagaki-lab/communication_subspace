{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.colors import CenteredNorm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and visualize data\n",
    "\n",
    "- 100 ms bins\n",
    "- 160 ms after stimulus onset\n",
    "- 1 s per trial\n",
    "- subtracted appropriate PSTH (response to drifting grating)\n",
    "- only firing rates > 0.5 Hz\n",
    "- mean-matched selection of units based on firing rates\n",
    "\n",
    "- varied bin sizes: 20 ms -> 1 s\n",
    "- shuffle control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "m = loadmat('./communication-subspace-master/mat_sample/sample_data.mat', squeeze_me=True, struct_as_record=False)\n",
    "X, Y_V1, Y_V2 = m['X'], m['Y_V1'], m['Y_V2']\n",
    "print(f'   X: {X.shape}')\n",
    "print(f'Y_V1: {Y_V1.shape}')\n",
    "print(f'Y_V2: {Y_V2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(ncols=3, figsize=(20, 4))\n",
    "for ax, data, t in zip(axarr, [X, Y_V1, Y_V2], ['source V1', 'target V1', 'target V2']):\n",
    "    nx, ny = data.shape\n",
    "    x = np.arange(nx) * .1\n",
    "    y = np.arange(ny) + 1\n",
    "\n",
    "    im = ax.pcolormesh(x, y, data.T) #, norm=CenteredNorm(), cmap='coolwarm')\n",
    "    \n",
    "    label = 'firing rate [Hz]'\n",
    "\n",
    "    fig.colorbar(im, ax=ax, location='right', orientation='vertical', label=label)\n",
    "    ax.set_xlabel('time [s]')\n",
    "    ax.set_ylabel('unit')\n",
    "    ax.set_title(t)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from custom_models import RRRegressor\n",
    "\n",
    "X, Y = X, Y_V2\n",
    "\n",
    "def nse(Y_true, Y_pred):\n",
    "        \n",
    "    dY_sq = (Y_pred - Y_true)**2\n",
    "    nse = np.sum(dY_sq) / np.sum(Y_true**2)\n",
    "\n",
    "    return nse\n",
    "\n",
    "\n",
    "def get_nse(mod, X, Y, n_fold=10):\n",
    "    \n",
    "    mod.fit(X, Y)\n",
    "    calc_nse = lambda model, X, Y: nse(Y, model.predict(X))\n",
    "    scores = cross_val_score(mod, X, Y_V2, cv=n_fold, scoring=calc_nse)\n",
    "    mean, std = np.mean(scores), np.std(scores)\n",
    "    ser = std / np.sqrt(len(scores))\n",
    "    \n",
    "    return mean, ser\n",
    "\n",
    "pred = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mod', LinearRegression())\n",
    "])\n",
    "\n",
    "pred['lin'] = get_nse(pipe, X, Y)\n",
    "\n",
    "# pipe.fit(X, Y)\n",
    "\n",
    "scores = cross_val_score(pipe, X, Y_V2, cv=10)\n",
    "lin_mean, lin_std = np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ridge \n",
    "l = np.logspace(0, 4, 100)\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mod', Ridge())\n",
    "])\n",
    "\n",
    "grd = GridSearchCV(\n",
    "    pipe, \n",
    "    { 'mod__alpha': l, },\n",
    "    cv=10,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "out = dict()\n",
    "\n",
    "mods = grd.fit(X, Y)\n",
    "mod = mods.best_estimator_\n",
    "\n",
    "# pred['ridge'] = cross_val_score(mod, X, Y_v2, cv=10)\n",
    "pred['ridge'] = get_nse(mod, X, Y)\n",
    "\n",
    "scores = cross_val_score(mod, X, Y_V2, cv=10)\n",
    "ridge_mean, ridge_std = np.mean(scores), np.std(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ridge\n",
    "df = pd.DataFrame(mods.cv_results_)\n",
    "x, y, yerr = df.loc[:, 'param_mod__alpha'], df.loc[:, 'mean_test_score'], df.loc[:, 'std_test_score']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.errorbar(x, y, yerr, label='ridge')\n",
    "ax.axhline(lin_mean, c='C1', label='linear')\n",
    "ax.axhline(lin_mean + lin_std, c='C1', ls='--')\n",
    "ax.axhline(lin_mean - lin_std, c='C1', ls='--')\n",
    "ax.legend()\n",
    "ax.set_xlabel('ridge parameter alpha')\n",
    "ax.set_ylabel('R2 score')\n",
    "\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced rank\n",
    "r = np.arange(Y.shape[1]) + 1\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('mod', RRRegressor())\n",
    "])\n",
    "\n",
    "grd = GridSearchCV(\n",
    "    pipe, \n",
    "    { 'mod__r': r, },\n",
    "    cv=10,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "out = dict()\n",
    "\n",
    "mods = grd.fit(X, Y)\n",
    "mod = mods.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RRR\n",
    "df = pd.DataFrame(mods.cv_results_)\n",
    "x, y, yerr = df.loc[:, 'param_mod__r'], df.loc[:, 'mean_test_score'], df.loc[:, 'std_test_score']\n",
    "\n",
    "fig, axarr = plt.subplots(ncols=2, figsize=(16, 5))\n",
    "ax = axarr[0]\n",
    "ax.errorbar(x, y, yerr, label='RR')\n",
    "ax.axhline(lin_mean, c='C1', label='linear')\n",
    "ax.axhline(lin_mean + lin_std, c='C1', ls='--')\n",
    "ax.axhline(lin_mean - lin_std, c='C1', ls='--')\n",
    "\n",
    "ax = axarr[1]\n",
    "ax.errorbar(x, y, yerr, label='RR')\n",
    "ax.axhline(ridge_mean, c='C2', label='ridge')\n",
    "ax.axhline(ridge_mean + ridge_std, c='C2', ls='--')\n",
    "ax.axhline(ridge_mean - ridge_std, c='C2', ls='--')\n",
    "\n",
    "for ax in axarr:\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlabel('RRR parameter r')\n",
    "    ax.set_ylabel('R2 score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mask = df.loc[:, 'n_comp'] < 100\n",
    "sns.lineplot(data=df.loc[ mask ], x='n_comp', y='NSE', errorbar='se', err_style='bars')\n",
    "\n",
    "mean, std = pred['lin']\n",
    "ax.axhline(mean, c='C0', label='linear')\n",
    "ax.axhline(mean + std, c='C0', ls='--', lw=0.5)\n",
    "ax.axhline(mean - std, c='C0', ls='--', lw=0.5)\n",
    "\n",
    "mean, std = pred['ridge']\n",
    "ax.axhline(mean, c='C1', label='ridge')\n",
    "ax.axhline(mean + std, c='C1', ls='--', lw=0.5)\n",
    "ax.axhline(mean - std, c='C1', ls='--', lw=0.5)\n",
    "\n",
    "nse_mat = loadmat('./communication-subspace-master/nse.mat', squeeze_me=True)['cvLoss']\n",
    "y = nse_mat[0]\n",
    "yerr = nse_mat[1]\n",
    "x = np.arange(len(y)) + 1\n",
    "ax.errorbar(x, y, yerr)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduced rank (ridge init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude neurons/folds with 0 variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bias(X):\n",
    "    'add bias (ones) to an N x p feature array'\n",
    "\n",
    "    bias = np.ones_like(X[:, :1])\n",
    "    Z = np.concatenate([bias, X], axis=1)\n",
    "\n",
    "    return Z\n",
    "\n",
    "\n",
    "def get_pca_components(X):\n",
    "    'calulate PCA components (columns of matrix V) for X (rows: observations, cols: variables)'\n",
    "    # PCA (alternatives: sklearn.decomposition.PCA or np.linalg.svd)\n",
    "    C = np.cov(X, rowvar=False)        # covariance matrix\n",
    "    val, vec = np.linalg.eig(C.T)         # diagonalize\n",
    "    V = vec[:, np.argsort(val)[::-1]]     # ensure descending components\n",
    "\n",
    "    # from sklearn.decomposition import PCA\n",
    "    # pca = PCA()\n",
    "    # pca.fit(Yf)\n",
    "    # V = pca.components_\n",
    "\n",
    "    # U, S, V = np.linalg.svd(Yf)\n",
    "\n",
    "    # V = loadmat('./communication-subspace-master/V.mat', squeeze_me=True)['V']\n",
    "\n",
    "    return V\n",
    "\n",
    "def lstsq_prediction(X, Y):\n",
    "\n",
    "   # least-squares solution\n",
    "    res = np.linalg.lstsq(X, Y, rcond=None) # lstsq(a, b) solves a * x = b\n",
    "    B = res[0]\n",
    "    Y_p = X @ B # predict targets \n",
    "\n",
    "    return Y_p, B\n",
    "\n",
    "def get_rr_weights(X, Y, n_components=None):\n",
    "\n",
    "    Y_ls, B_ls = lstsq_prediction(X, Y)\n",
    "\n",
    "    V = get_pca_components(Y_ls)\n",
    "\n",
    "    n = n_components if n_components else V.shape[1] \n",
    "\n",
    "    l = []\n",
    "    Y_m = Y.mean(axis=0)\n",
    "    for i in range(n):\n",
    "\n",
    "        V_i = V[:, :i+1]            # first i principle components\n",
    "        B_i = B_ls @ V_i @ V_i.T    # enforcing low rank on B_ls\n",
    "\n",
    "        # # add bias term TODO: check if this can be done earlier\n",
    "        # bias = Y.mean(axis=0) - (X.mean(axis=0) @ B_i)\n",
    "        # bias = np.expand_dims(bias, axis=0)\n",
    "        # B_i = np.concatenate([bias, B_i], axis=0)\n",
    "\n",
    "        l.append(B_i)\n",
    "\n",
    "    B = np.array(l)\n",
    "\n",
    "    return B\n",
    "\n",
    "def calculate_score(X, B, Y, scorer):\n",
    "    'expects specific strucutre for B TODO'\n",
    "\n",
    "    # predict Y\n",
    "    Y_p = np.tensordot(X, B, axes=(1, 1))\n",
    "    Y_p = np.moveaxis(Y_p, 0, 1)\n",
    "\n",
    "    if scorer == 'MSE':\n",
    "        \n",
    "        dY_sq = (Y_p - Y)**2\n",
    "        scr = np.mean(dY_sq, axis=(1, 2))\n",
    "\n",
    "        return scr\n",
    "\n",
    "    elif scorer == 'NSE':\n",
    "        dY_sq = (Y_p - Y)**2\n",
    "\n",
    "        a = np.sum(dY_sq, axis=(1, 2))  # sum of squared errors\n",
    "        b = np.sum(Y**2)                # sum of squared targets\n",
    "        scr = a / b\n",
    "        \n",
    "        return scr\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f'Scorer type {scorer} not implemented')\n",
    "\n",
    "def pipe(X, Y, n_fold=10, n_components=None):\n",
    "    \n",
    "    X = add_bias(X)\n",
    "\n",
    "    ds = []\n",
    "    for i, (i_train, i_test) in enumerate(KFold(n_fold).split(X)):\n",
    "\n",
    "        x_train, y_train = X[i_train], Y[i_train]\n",
    "        x_test, y_test = X[i_test], Y[i_test]\n",
    "\n",
    "        B = get_rr_weights(x_train, y_train, n_components=n_components)\n",
    "        \n",
    "        # x_test = add_bias(x_test)\n",
    "        \n",
    "        score = calculate_score(x_test, B, y_test, scorer='NSE')\n",
    "        d = pd.DataFrame(data={\n",
    "            'NSE' : score,\n",
    "            'n_fold': i + 1,\n",
    "            'n_comp': np.arange(len(score)) + 1\n",
    "        })\n",
    "        ds.append(d)\n",
    "    \n",
    "    df = pd.concat(ds, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = pipe(X, Y, n_components=10)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cupy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
